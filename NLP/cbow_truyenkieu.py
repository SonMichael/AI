# -*- coding: utf-8 -*-
"""CBOW-TruyenKieu.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S-GU1IcKHSo06pEVPBvdo1alpxxjtoVg

## 1. Tải dữ liệu
"""

!wget --no-check-certificate \
    https://gist.githubusercontent.com/khacanh/4c4662fa226db87a4664dfc2f70bc63e/raw/5d8a1d890c73a1e92e6898137db28f3dc0676975/kieu.txt \
    -O ./kieu.txt

"""Load các dòng thơ"""

corpus = []
f = open("kieu.txt", "r")
for line in f:
  corpus.append(line)

len(corpus)

corpus = corpus[:500]

corpus[501]

"""Kiểm tra các dòng thơ"""

corpus

"""## 2. Xây dựng tokenizer"""

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import text_to_word_sequence

for i in range(len(corpus)):
  corpus[i] = text_to_word_sequence(corpus[i])

corpus

tokenizer = Tokenizer(oov_token='<OOV>')
tokenizer.fit_on_texts(corpus)
w2id = tokenizer.word_index

w2id

from tensorflow.keras.utils import to_categorical

"""## 3. Xử lý dữ liệu cho CBOW"""

vocab_size = len(tokenizer.word_index) + 1
window_size = 2

import numpy as np
def generate_pairs(window_size, corpus):
  """
  Tiến hành lấy 1 từ khỏi câu làm nhãn và sử dụng câu bao
  gồm k từ bên trái và k từ bên phải (trường hợp này window_size = k) làm đầu vào

  Đầu vào:
    window_size:
      Dạng: Python integer 
      Miêu tả: k từ bên trái/phải được giữ lại
    corpus: 
      Dạng: Python Dictionary
      Miêu tả: từ điển nối từ và id
  """
  X = []
  y = []
  for words in corpus:
    start = 0
    while start + window_size * 2 < len(words):
      end = start + window_size * 2
      tar_i = start + window_size

      # Lựa chọn từ ở vị trí hiện tại làm nhãn
      label = words[tar_i]

      # Nối k từ bên trái và k từ bên phải của từ này thành 1 câu
      x = [" ".join(words[start:tar_i] + words[tar_i+1:end+1])]

      print(words)
      print(x, "--->", label)
      start += 1
      X.append(tokenizer.texts_to_sequences(x)[0])
      y.append(to_categorical( tokenizer.word_index[label], len(tokenizer.word_index) + 1))

  return tf.convert_to_tensor(X) , tf.convert_to_tensor(y)

X_train, y_train = generate_pairs(window_size, corpus)

X_train

"""## 4. Xây dựng mô hình

Mô hình CBOW bao gồm
- 1 lớp Embedding với chiều được định sẵn
- 1 lớp Dense để phóng về chiều từ điển
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Embedding, Lambda
from tensorflow.keras.backend import mean

"""Kiểm tra mô hình"""

embedding_size = 128
cbow = Sequential()

cbow.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=window_size*2))

cbow.add(Lambda(lambda x: mean(x, axis=1), output_shape=(embedding_size,) ))
cbow.add(Dense(vocab_size, activation='softmax'))

cbow.summary()

"""## 5. Tiến hành training"""

cbow.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])
cbow.fit(X_train, y_train, epochs=30, verbose=1)

"""6. Kiểm tra sinh từ"""

example = 'Trăm năm cõi người'
example = text_to_word_sequence(example)
example = tokenizer.texts_to_sequences([example])
example = tf.convert_to_tensor(example)
cbow.predict(example)
tokenizer.index_word[np.argmax(cbow.predict(example))]

example = 'Dẽ cho hết một'
example = text_to_word_sequence(example)
example = tokenizer.texts_to_sequences([example])
example = tf.convert_to_tensor(example)
cbow.predict(example)
tokenizer.index_word[np.argmax(cbow.predict(example))]

"""## 6. Hiển thị Embedding"""

weights = cbow.get_weights()[0]

weights

import pandas as pd
weights = cbow.get_weights()[0]
weights = weights[1:]
print(weights.shape)

pd.DataFrame(weights, index=list(tokenizer.index_word.values())).head()